#!/usr/bin/env python3
"""
Web API for GeekDaily articles
ä¸ºç½‘é¡µåº”ç”¨æä¾›æ•°æ®è®¿é—®æ¥å£
"""

from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional, List, Dict, Any
import uvicorn
from datetime import datetime
import json
from storage.database import DatabaseManager
from utils.logger import logger
from analytics.trend_analyzer import TrendAnalyzer
from analytics.tag_extractor import TagExtractor
from analytics.content_evaluator import ContentEvaluator

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="GeekDaily Articles API",
    description="ä¸ºWeb3æå®¢æ—¥æŠ¥æ•°æ®æä¾›REST APIæ¥å£",
    version="1.0.0"
)

# ç¯å¢ƒé…ç½®
import os
from typing import List

# è·å–ç¯å¢ƒå˜é‡
CORS_ORIGINS = os.getenv("CORS_ORIGINS", '["*"]')
if isinstance(CORS_ORIGINS, str):
    import json
    try:
        CORS_ORIGINS = json.loads(CORS_ORIGINS)
    except:
        CORS_ORIGINS = ["*"]

# é…ç½®CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# æ•°æ®åº“è¿æ¥
db = None

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
    global db
    db = DatabaseManager(use_mongodb=False)
    logger.info("Web API started successfully")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ¸…ç†èµ„æº"""
    global db
    if db:
        db.close()
    logger.info("Web API shutdown")

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - APIä¿¡æ¯"""
    return {
        "message": "GeekDaily Articles API",
        "version": "1.0.0",
        "endpoints": {
            "articles": "/articles - è·å–æ–‡ç« åˆ—è¡¨",
            "articles_by_id": "/articles/{id} - è·å–ç‰¹å®šæ–‡ç« ",
            "search": "/articles/search - æœç´¢æ–‡ç« ",
            "stats": "/stats - ç»Ÿè®¡ä¿¡æ¯",
            "accounts": "/accounts - è´¦å·åˆ—è¡¨"
        }
    }

@app.get("/articles")
async def get_articles(
    account: Optional[str] = Query(None, description="è´¦å·åç§°ç­›é€‰"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›æ•°é‡é™åˆ¶ (1-100)"),
    offset: int = Query(0, ge=0, description="è·³è¿‡æ•°é‡"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯")
):
    """
    è·å–æ–‡ç« åˆ—è¡¨
    
    å‚æ•°:
    - account: å¯é€‰ï¼Œç­›é€‰ç‰¹å®šè´¦å·çš„æ–‡ç« 
    - limit: è¿”å›æ•°é‡é™åˆ¶ï¼Œé»˜è®¤20ï¼Œæœ€å¤§100
    - offset: è·³è¿‡çš„æ•°é‡ï¼Œç”¨äºåˆ†é¡µ
    - search: å¯é€‰ï¼Œæœç´¢å…³é”®è¯
    """
    try:
        if search:
            articles = db.search_articles(search, limit)
        else:
            articles = db.get_articles_by_account(account or "", limit, offset)
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        formatted_articles = []
        for article in articles:
            formatted_article = {
                "id": article.get('id'),
                "title": article.get('title', ''),
                "author": article.get('author', ''),
                "account_name": article.get('account_name', ''),
                "url": article.get('url', ''),
                "publish_time": article.get('publish_time', ''),
                "content_preview": (article.get('content', '') or '')[:200],  # å†…å®¹é¢„è§ˆ
                "content_length": len(article.get('content', '') or ''),
                "crawl_time": article.get('crawl_time', ''),
                "read_count": article.get('read_count', 0),
                "like_count": article.get('like_count', 0)
            }
            formatted_articles.append(formatted_article)
        
        # è·å–æ€»æ•°ï¼ˆç”¨äºåˆ†é¡µï¼‰
        total_count = db.get_article_count(account)
        
        return {
            "success": True,
            "data": {
                "articles": formatted_articles,
                "pagination": {
                    "total": total_count,
                    "limit": limit,
                    "offset": offset,
                    "has_more": offset + limit < total_count
                }
            },
            "message": f"è¿”å› {len(formatted_articles)} ç¯‡æ–‡ç« "
        }
        
    except Exception as e:
        logger.error(f"è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ç« å¤±è´¥: {str(e)}")

@app.get("/search")
async def search_articles(
    q: str = Query(..., description="æœç´¢å…³é”®è¯"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›æ•°é‡é™åˆ¶")
):
    """
    æœç´¢æ–‡ç« 
    
    å‚æ•°:
    - q: æœç´¢å…³é”®è¯ï¼ˆå¿…éœ€ï¼‰
    - limit: è¿”å›æ•°é‡é™åˆ¶ï¼Œé»˜è®¤20ï¼Œæœ€å¤§100
    """
    try:
        articles = db.search_articles(q, limit)
        
        formatted_articles = []
        for article in articles:
            formatted_article = {
                "id": article.get('id'),
                "title": article.get('title', ''),
                "author": article.get('author', ''),
                "account_name": article.get('account_name', ''),
                "url": article.get('url', ''),
                "publish_time": article.get('publish_time', ''),
                "content_preview": (article.get('content', '') or '')[:300],
                "crawl_time": article.get('crawl_time', '')
            }
            formatted_articles.append(formatted_article)
        
        return {
            "success": True,
            "data": {
                "articles": formatted_articles,
                "query": q,
                "count": len(formatted_articles)
            },
            "message": f"æœç´¢åˆ° {len(formatted_articles)} ç¯‡ç›¸å…³æ–‡ç« "
        }
        
    except Exception as e:
        logger.error(f"æœç´¢æ–‡ç« å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")

@app.get("/articles/{article_id}")
async def get_article_by_id(article_id: int):
    """
    è·å–ç‰¹å®šæ–‡ç« çš„è¯¦ç»†ä¿¡æ¯
    
    å‚æ•°:
    - article_id: æ–‡ç« ID
    """
    try:
        # é€šè¿‡IDæŸ¥è¯¢æ–‡ç« 
        if db.use_mongodb:
            article = db.articles_collection.find_one({"id": article_id})
        else:
            with db.get_session() as session:
                from storage.models import ArticleDB
                article_obj = session.query(ArticleDB).filter_by(id=article_id).first()
                article = article_obj.to_dict() if article_obj else None
        
        if not article:
            raise HTTPException(status_code=404, detail=f"æ–‡ç« ID {article_id} æœªæ‰¾åˆ°")
        
        return {
            "success": True,
            "data": {
                "id": article.get('id'),
                "title": article.get('title', ''),
                "author": article.get('author', ''),
                "account_name": article.get('account_name', ''),
                "url": article.get('url', ''),
                "content": article.get('content', ''),
                "publish_time": article.get('publish_time', ''),
                "crawl_time": article.get('crawl_time', ''),
                "images": article.get('images', []),
                "cover_image": article.get('cover_image', ''),
                "read_count": article.get('read_count', 0),
                "like_count": article.get('like_count', 0),
                "comment_count": article.get('comment_count', 0)
            },
            "message": "æ–‡ç« è¯¦æƒ…è·å–æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡ç« è¯¦æƒ…å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ç« è¯¦æƒ…å¤±è´¥: {str(e)}")

@app.get("/articles/search")
async def search_articles(
    q: str = Query(..., description="æœç´¢å…³é”®è¯"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›æ•°é‡é™åˆ¶")
):
    """
    æœç´¢æ–‡ç« 
    
    å‚æ•°:
    - q: æœç´¢å…³é”®è¯ï¼ˆå¿…éœ€ï¼‰
    - limit: è¿”å›æ•°é‡é™åˆ¶ï¼Œé»˜è®¤20ï¼Œæœ€å¤§100
    """
    try:
        articles = db.search_articles(q, limit)
        
        formatted_articles = []
        for article in articles:
            formatted_article = {
                "id": article.get('id'),
                "title": article.get('title', ''),
                "author": article.get('author', ''),
                "account_name": article.get('account_name', ''),
                "url": article.get('url', ''),
                "publish_time": article.get('publish_time', ''),
                "content_preview": (article.get('content', '') or '')[:300],
                "crawl_time": article.get('crawl_time', '')
            }
            formatted_articles.append(formatted_article)
        
        return {
            "success": True,
            "data": {
                "articles": formatted_articles,
                "query": q,
                "count": len(formatted_articles)
            },
            "message": f"æœç´¢åˆ° {len(formatted_articles)} ç¯‡ç›¸å…³æ–‡ç« "
        }
        
    except Exception as e:
        logger.error(f"æœç´¢æ–‡ç« å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")

@app.get("/stats")
async def get_stats():
    """
    è·å–ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        total_articles = db.get_article_count()
        
        # è·å–æ‰€æœ‰æ–‡ç« æ¥åˆ†æè´¦å·åˆ†å¸ƒ
        all_articles = db.get_articles_by_account("", limit=10000)
        
        # ç»Ÿè®¡è´¦å·åˆ†å¸ƒ
        accounts = {}
        authors = {}
        recent_articles = []
        
        for article in all_articles:
            # è´¦å·ç»Ÿè®¡
            account_name = article.get('account_name', 'Unknown')
            accounts[account_name] = accounts.get(account_name, 0) + 1
            
            # ä½œè€…ç»Ÿè®¡
            author = article.get('author', 'Unknown')
            authors[author] = authors.get(author, 0) + 1
            
            # æœ€è¿‘æ–‡ç« ï¼ˆå–å‰10ç¯‡ï¼‰
            if len(recent_articles) < 10:
                recent_articles.append({
                    "id": article.get('id'),
                    "title": article.get('title', ''),
                    "author": author,
                    "account_name": account_name,
                    "publish_time": article.get('publish_time', ''),
                    "url": article.get('url', '')
                })
        
        # æ’åºç»Ÿè®¡æ•°æ®
        top_accounts = sorted(accounts.items(), key=lambda x: x[1], reverse=True)[:10]
        top_authors = sorted(authors.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "success": True,
            "data": {
                "overview": {
                    "total_articles": total_articles,
                    "total_accounts": len(accounts),
                    "total_authors": len(authors)
                },
                "top_accounts": [{"name": name, "count": count} for name, count in top_accounts],
                "top_authors": [{"name": name, "count": count} for name, count in top_authors],
                "recent_articles": recent_articles
            },
            "message": "ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")

@app.get("/accounts")
async def get_accounts():
    """
    è·å–æ‰€æœ‰è´¦å·åˆ—è¡¨
    """
    try:
        all_articles = db.get_articles_by_account("", limit=10000)
        
        # ç»Ÿè®¡è´¦å·ä¿¡æ¯
        accounts_info = {}
        for article in all_articles:
            account_name = article.get('account_name', 'Unknown')
            if account_name not in accounts_info:
                accounts_info[account_name] = {
                    "name": account_name,
                    "article_count": 0,
                    "latest_article": None,
                    "authors": set()
                }
            
            accounts_info[account_name]["article_count"] += 1
            accounts_info[account_name]["authors"].add(article.get('author', 'Unknown'))
            
            # æ›´æ–°æœ€æ–°æ–‡ç« ï¼ˆç®€å•æ ¹æ®å¤„ç†é¡ºåºï¼‰
            if not accounts_info[account_name]["latest_article"]:
                accounts_info[account_name]["latest_article"] = {
                    "title": article.get('title', ''),
                    "publish_time": article.get('publish_time', ''),
                    "url": article.get('url', '')
                }
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        accounts_list = []
        for account_info in accounts_info.values():
            account_info["author_count"] = len(account_info["authors"])
            account_info["authors"] = list(account_info["authors"])
            accounts_list.append(account_info)
        
        # æŒ‰æ–‡ç« æ•°é‡æ’åº
        accounts_list.sort(key=lambda x: x["article_count"], reverse=True)
        
        return {
            "success": True,
            "data": {
                "accounts": accounts_list,
                "total_accounts": len(accounts_list)
            },
            "message": f"è¿”å› {len(accounts_list)} ä¸ªè´¦å·ä¿¡æ¯"
        }
        
    except Exception as e:
        logger.error(f"è·å–è´¦å·åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è´¦å·åˆ—è¡¨å¤±è´¥: {str(e)}")

# Analytics API Endpoints

@app.get("/analytics/trends")
async def get_technology_trends(
    days: int = Query(30, ge=1, le=365, description="åˆ†æå¤©æ•°ï¼Œé»˜è®¤30å¤©")
):
    """
    è·å–æŠ€æœ¯è¶‹åŠ¿åˆ†æ
    
    å‚æ•°:
    - days: åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤30å¤©ï¼Œæœ€å¤§365å¤©
    """
    try:
        analyzer = TrendAnalyzer()
        results = analyzer.analyze_technology_trends(days)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        return {
            "success": True,
            "data": results,
            "message": f"æŠ€æœ¯è¶‹åŠ¿åˆ†æå®Œæˆï¼ˆæœ€è¿‘{days}å¤©ï¼‰"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æŠ€æœ¯è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æŠ€æœ¯è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")

@app.get("/analytics/authors")
async def get_author_activity(
    days: int = Query(30, ge=1, le=365, description="åˆ†æå¤©æ•°ï¼Œé»˜è®¤30å¤©")
):
    """
    è·å–ä½œè€…æ´»è·ƒåº¦åˆ†æ
    
    å‚æ•°:
    - days: åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤30å¤©ï¼Œæœ€å¤§365å¤©
    """
    try:
        analyzer = TrendAnalyzer()
        results = analyzer.analyze_author_activity(days)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        return {
            "success": True,
            "data": results,
            "message": f"ä½œè€…æ´»è·ƒåº¦åˆ†æå®Œæˆï¼ˆæœ€è¿‘{days}å¤©ï¼‰"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä½œè€…æ´»è·ƒåº¦åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä½œè€…æ´»è·ƒåº¦åˆ†æå¤±è´¥: {str(e)}")

@app.get("/analytics/publishing")
async def get_publication_patterns(
    days: int = Query(90, ge=1, le=365, description="åˆ†æå¤©æ•°ï¼Œé»˜è®¤90å¤©")
):
    """
    è·å–å‘å¸ƒæ¨¡å¼åˆ†æ
    
    å‚æ•°:
    - days: åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤90å¤©ï¼Œæœ€å¤§365å¤©
    """
    try:
        analyzer = TrendAnalyzer()
        results = analyzer.analyze_publication_patterns(days)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        return {
            "success": True,
            "data": results,
            "message": f"å‘å¸ƒæ¨¡å¼åˆ†æå®Œæˆï¼ˆæœ€è¿‘{days}å¤©ï¼‰"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å‘å¸ƒæ¨¡å¼åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å‘å¸ƒæ¨¡å¼åˆ†æå¤±è´¥: {str(e)}")

@app.get("/analytics/report")
async def get_comprehensive_report(
    days: int = Query(30, ge=1, le=365, description="åˆ†æå¤©æ•°ï¼Œé»˜è®¤30å¤©")
):
    """
    è·å–ç»¼åˆåˆ†ææŠ¥å‘Š
    
    å‚æ•°:
    - days: åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤30å¤©ï¼Œæœ€å¤§365å¤©
    """
    try:
        analyzer = TrendAnalyzer()
        results = analyzer.get_comprehensive_trends(days)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        return {
            "success": True,
            "data": results,
            "message": f"ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼ˆæœ€è¿‘{days}å¤©ï¼‰"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")

@app.get("/analytics/tags/extract")
async def extract_article_tags(
    limit: Optional[int] = Query(None, ge=1, le=1000, description="å¤„ç†æ–‡ç« æ•°é‡é™åˆ¶")
):
    """
    æå–æ–‡ç« æ ‡ç­¾
    
    å‚æ•°:
    - limit: å¤„ç†æ–‡ç« æ•°é‡é™åˆ¶ï¼Œé»˜è®¤å¤„ç†æ‰€æœ‰æ–‡ç« 
    """
    try:
        extractor = TagExtractor()
        results = extractor.batch_tag_articles(limit=limit)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        return {
            "success": True,
            "data": results,
            "message": f"æ ‡ç­¾æå–å®Œæˆï¼Œå¤„ç†äº†{results['summary']['successfully_tagged']}ç¯‡æ–‡ç« "
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ ‡ç­¾æå–å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ ‡ç­¾æå–å¤±è´¥: {str(e)}")

@app.get("/analytics/tags/trends")
async def get_tag_trends(
    days: int = Query(30, ge=1, le=365, description="åˆ†æå¤©æ•°ï¼Œé»˜è®¤30å¤©")
):
    """
    è·å–æ ‡ç­¾è¶‹åŠ¿åˆ†æ
    
    å‚æ•°:
    - days: åˆ†ææ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤30å¤©ï¼Œæœ€å¤§365å¤©
    """
    try:
        extractor = TagExtractor()
        results = extractor.analyze_tag_trends(days)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        return {
            "success": True,
            "data": results,
            "message": f"æ ‡ç­¾è¶‹åŠ¿åˆ†æå®Œæˆï¼ˆæœ€è¿‘{days}å¤©ï¼‰"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ ‡ç­¾è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ ‡ç­¾è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")

@app.get("/analytics/quality/evaluate")
async def evaluate_content_quality(
    limit: Optional[int] = Query(None, ge=1, le=1000, description="è¯„ä¼°æ–‡ç« æ•°é‡é™åˆ¶")
):
    """
    è¯„ä¼°å†…å®¹è´¨é‡
    
    å‚æ•°:
    - limit: è¯„ä¼°æ–‡ç« æ•°é‡é™åˆ¶ï¼Œé»˜è®¤è¯„ä¼°æ‰€æœ‰æ–‡ç« 
    """
    try:
        evaluator = ContentEvaluator()
        results = evaluator.batch_evaluate_quality(limit=limit)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        return {
            "success": True,
            "data": results,
            "message": f"å†…å®¹è´¨é‡è¯„ä¼°å®Œæˆï¼Œè¯„ä¼°äº†{results['summary']['successfully_evaluated']}ç¯‡æ–‡ç« "
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å†…å®¹è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å†…å®¹è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}")

@app.get("/analytics/quality/insights")
async def get_quality_insights(
    min_score: float = Query(0.7, ge=0.0, le=1.0, description="é«˜è´¨é‡æ–‡ç« æœ€ä½è¯„åˆ†")
):
    """
    è·å–è´¨é‡æ´å¯ŸæŠ¥å‘Š
    
    å‚æ•°:
    - min_score: é«˜è´¨é‡æ–‡ç« æœ€ä½è¯„åˆ†ï¼ˆ0.0-1.0ï¼‰ï¼Œé»˜è®¤0.7
    """
    try:
        evaluator = ContentEvaluator()
        results = evaluator.get_quality_insights(min_quality_score=min_score)
        
        if "error" in results:
            raise HTTPException(status_code=500, detail=results["error"])
        
        return {
            "success": True,
            "data": results,
            "message": f"è´¨é‡æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼ˆæœ€ä½è¯„åˆ†â‰¥{min_score}ï¼‰"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è´¨é‡æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è´¨é‡æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        total_articles = db.get_article_count()
        
        return {
            "success": True,
            "data": {
                "status": "healthy",
                "database": "connected",
                "total_articles": total_articles,
                "timestamp": datetime.now().isoformat()
            },
            "message": "APIè¿è¡Œæ­£å¸¸"
        }
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")

def run_server(host: str = "127.0.0.1", port: int = 8000, reload: bool = False):
    """å¯åŠ¨Web APIæœåŠ¡å™¨"""
    print(f"ğŸš€ å¯åŠ¨GeekDaily Articles APIæœåŠ¡å™¨...")
    print(f"ğŸ“¡ æœåŠ¡åœ°å€: http://{host}:{port}")
    print(f"ğŸ“– APIæ–‡æ¡£: http://{host}:{port}/docs")
    print(f"ğŸ“Š äº¤äº’å¼æ–‡æ¡£: http://{host}:{port}/redoc")
    print()
    print(f"ğŸ”§ å¯ç”¨ç«¯ç‚¹:")
    print(f"  GET  /articles                     - è·å–æ–‡ç« åˆ—è¡¨")
    print(f"  GET  /articles/{{id}}                - è·å–ç‰¹å®šæ–‡ç« ")
    print(f"  GET  /articles/search              - æœç´¢æ–‡ç« ")
    print(f"  GET  /stats                       - ç»Ÿè®¡ä¿¡æ¯")
    print(f"  GET  /accounts                    - è´¦å·åˆ—è¡¨")
    print(f"  GET  /analytics/trends            - æŠ€æœ¯è¶‹åŠ¿åˆ†æ")
    print(f"  GET  /analytics/authors           - ä½œè€…æ´»è·ƒåº¦åˆ†æ")
    print(f"  GET  /analytics/publishing        - å‘å¸ƒæ¨¡å¼åˆ†æ")
    print(f"  GET  /analytics/report            - ç»¼åˆåˆ†ææŠ¥å‘Š")
    print(f"  GET  /analytics/tags/extract      - æ™ºèƒ½æ ‡ç­¾æå–")
    print(f"  GET  /analytics/tags/trends       - æ ‡ç­¾è¶‹åŠ¿åˆ†æ")
    print(f"  GET  /analytics/quality/evaluate  - å†…å®¹è´¨é‡è¯„ä¼°")
    print(f"  GET  /analytics/quality/insights  - è´¨é‡æ´å¯ŸæŠ¥å‘Š")
    print(f"  GET  /health                      - å¥åº·æ£€æŸ¥")
    print()
    
    try:
        uvicorn.run(
            "web_api:app",
            host=host,
            port=port,
            reload=reload,
            log_level="info"
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ APIæœåŠ¡å™¨å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ APIæœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="GeekDaily Articles Web API")
    parser.add_argument('--host', default='127.0.0.1', help='Host address (default: 127.0.0.1)')
    parser.add_argument('--port', type=int, default=8000, help='Port number (default: 8000)')
    parser.add_argument('--reload', action='store_true', help='Enable auto-reload for development')
    
    args = parser.parse_args()
    
    run_server(host=args.host, port=args.port, reload=args.reload)